{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3907c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4de91d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.txt\",'r',encoding='utf-8') as f :\n",
    "    text_data  = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bffef99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nMaking an Impact\\nHelping Millions of Students Succeed\\nSudhanshu's commitment to affordable education wasn't just a business strategy—it was his life's mission. Over the years, iNeuron has helped over 1.5 million students from 34+ countries, providing them with the skills they need to succeed in today's competitive job market. Many of these students, like Sudhanshu himself, came from disadvantaged backgrounds. They saw iNeuron as a lifeline—an opportunity to rise above their circumstances.\\n\\nIn 2022, iNeuron was acquired by PhysicsWallah in a deal worth ₹250 crore. While this acquisition was a significant milestone, Sudhanshu remained focused on his mission. Even after the acquisition, iNeuron continued to offer some of the most affordable and accessible tech courses in the world.\\n\\nThe Entrepreneur and Teacher: Sudhanshu's Dual Legacy\\nSudhanshu's journey isn't just one of entrepreneurial success; it's also a story of dedication to teaching. Throughout his career, he has remained a passionate educator, constantly looking for ways to empower others through knowledge. Whether teaching courses in Big Data, Data Science, or programming, Sudhanshu has always sought to make complex subjects accessible to learners at all levels.\\n\\nHis commitment to affordable education has earned him the respect and admiration of countless students. Many credit Sudhanshu with changing their lives, helping them secure jobs, improve their skills, and break free from the limitations of their backgrounds.\\n\\n\\nSudhanshu Kumar's life is a story of triumph over adversity, driven by the belief in the transformative power of education. Born in Jamshedpur, Jharkhand, India, to a family of very modest means, Sudhanshu's early years were marked by financial hardship. His surroundings offered little opportunity, and resources were limited, yet he understood from a young age that education could be his ticket out of poverty.\\n\\nWhile many would have been daunted by the lack of support and opportunity, Sudhanshu was relentless in his pursuit of knowledge. He knew that education had the power to change lives, and he was determined to leverage it to create a better future for himself and his family. Despite the numerous challenges along the way, Sudhanshu excelled academically, eventually earning a degree in Computer Science and Engineering (CSE).\\n\\nAfter completing his education, Sudhanshu began his professional journey in the tech industry, working with prestigious companies like Wipro, Deloitte, Verizon Labs, and Ernst & Young. During this time, he gained expertise in various technologies and frameworks, including SAP WebDynpro, Fiori UI5 HANA, Java, Big Data, Data Analytics, and more. He became a well-rounded technologist, well-respected in his field.\\n\\nDespite his growing success, Sudhanshu never forgot his roots. He knew that there were many others who, like him, came from humble backgrounds and were looking for an opportunity to change their lives through education. It was during this time that Sudhanshu realized a harsh truth: quality education was often inaccessible to those who needed it the most. The high cost of education barred millions of people from pursuing their dreams, especially in tech fields that required specialized skills.\\n\\nFueled by his passion for making education accessible, Sudhanshu decided to take action. In 2019, he founded iNeuron Intelligence Private Limited, an edtech platform that would make tech upskilling affordable and accessible for everyone. His mission was clear: to provide high-quality courses at a price so low that even those from the most disadvantaged backgrounds could afford to learn.\\n\\niNeuron was designed to be more than just an online learning platform. It offered a comprehensive bundle of resources, including courses, books, hands-on projects, and live classes, making sure that learners could gain real-world, applicable skills. Most importantly, iNeuron was priced to ensure no student would be left behind due to financial constraints.\\n\\nThe company quickly gained traction, thanks to Sudhanshu's focus on affordability and quality. In 2021, iNeuron raised $3 million in funding from S. Chand, a leading education publisher. This allowed iNeuron to expand its offerings and reach a larger audience.\\n\\nBuilding on the success of iNeuron, Sudhanshu is now leading Euron, a unified platform for tech upskilling. Euron is designed for enterprises, schools, colleges, government organizations, and individuals looking to improve their tech skills. The platform provides a comprehensive bundle of resources, including courses, books, live classes, and projects. Euron's unique offering is its ability to provide licenses at scale—organizations can subscribe to provide their teams with unlimited access to learning materials for just 1600 INR per year per license.\\n\\nFor individuals, Euron Plus offers a similar plan, priced at 2900 INR per year, giving learners access to all of Euron's content, along with 24/7 support through Euron Assist. The idea is simple: anyone, anywhere, should have the opportunity to upskill without financial barriers.\\n\\nThe Euron Motto: Education for All, Without Limits\\n\\nAt the heart of Euron's philosophy is a single, powerful idea: Education for All, Without Limits. Sudhanshu believes that every person deserves the chance to learn, grow, and succeed, regardless of their financial situation or background. This belief is what drives Euron's mission to make tech education not just affordable but also accessible to anyone, anywhere in the world.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ecf237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=5000,oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts([text_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29f1239a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.text.Tokenizer at 0x17a46a1f130>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73932b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = tokenizer.texts_to_sequences([text_data])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d09b6a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[47,\n",
       " 32,\n",
       " 134,\n",
       " 67,\n",
       " 68,\n",
       " 4,\n",
       " 33,\n",
       " 48,\n",
       " 20,\n",
       " 69,\n",
       " 2,\n",
       " 21,\n",
       " 9,\n",
       " 135,\n",
       " 22,\n",
       " 5,\n",
       " 136,\n",
       " 137,\n",
       " 12,\n",
       " 8,\n",
       " 138,\n",
       " 34,\n",
       " 49,\n",
       " 3,\n",
       " 70,\n",
       " 13,\n",
       " 35,\n",
       " 139,\n",
       " 49,\n",
       " 140,\n",
       " 141,\n",
       " 71,\n",
       " 33,\n",
       " 16,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 72,\n",
       " 23,\n",
       " 3,\n",
       " 24,\n",
       " 73,\n",
       " 145,\n",
       " 2,\n",
       " 48,\n",
       " 7,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 36,\n",
       " 4,\n",
       " 150,\n",
       " 33,\n",
       " 50,\n",
       " 10,\n",
       " 74,\n",
       " 75,\n",
       " 16,\n",
       " 76,\n",
       " 37,\n",
       " 73,\n",
       " 151,\n",
       " 13,\n",
       " 152,\n",
       " 5,\n",
       " 153,\n",
       " 25,\n",
       " 2,\n",
       " 154,\n",
       " 155,\n",
       " 14,\n",
       " 156,\n",
       " 7,\n",
       " 157,\n",
       " 13,\n",
       " 12,\n",
       " 158,\n",
       " 26,\n",
       " 159,\n",
       " 7,\n",
       " 5,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 77,\n",
       " 27,\n",
       " 78,\n",
       " 12,\n",
       " 5,\n",
       " 164,\n",
       " 165,\n",
       " 10,\n",
       " 79,\n",
       " 166,\n",
       " 38,\n",
       " 8,\n",
       " 34,\n",
       " 80,\n",
       " 81,\n",
       " 3,\n",
       " 78,\n",
       " 13,\n",
       " 167,\n",
       " 2,\n",
       " 168,\n",
       " 169,\n",
       " 4,\n",
       " 3,\n",
       " 39,\n",
       " 21,\n",
       " 6,\n",
       " 28,\n",
       " 18,\n",
       " 29,\n",
       " 7,\n",
       " 3,\n",
       " 51,\n",
       " 3,\n",
       " 170,\n",
       " 6,\n",
       " 171,\n",
       " 20,\n",
       " 172,\n",
       " 173,\n",
       " 20,\n",
       " 82,\n",
       " 174,\n",
       " 22,\n",
       " 175,\n",
       " 4,\n",
       " 176,\n",
       " 52,\n",
       " 177,\n",
       " 83,\n",
       " 5,\n",
       " 84,\n",
       " 4,\n",
       " 178,\n",
       " 2,\n",
       " 85,\n",
       " 179,\n",
       " 8,\n",
       " 180,\n",
       " 17,\n",
       " 35,\n",
       " 79,\n",
       " 5,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 53,\n",
       " 11,\n",
       " 184,\n",
       " 2,\n",
       " 185,\n",
       " 86,\n",
       " 54,\n",
       " 87,\n",
       " 186,\n",
       " 85,\n",
       " 29,\n",
       " 7,\n",
       " 88,\n",
       " 40,\n",
       " 40,\n",
       " 89,\n",
       " 90,\n",
       " 187,\n",
       " 10,\n",
       " 35,\n",
       " 188,\n",
       " 189,\n",
       " 2,\n",
       " 55,\n",
       " 190,\n",
       " 191,\n",
       " 28,\n",
       " 2,\n",
       " 56,\n",
       " 30,\n",
       " 41,\n",
       " 192,\n",
       " 8,\n",
       " 69,\n",
       " 2,\n",
       " 21,\n",
       " 9,\n",
       " 35,\n",
       " 193,\n",
       " 91,\n",
       " 3,\n",
       " 194,\n",
       " 6,\n",
       " 195,\n",
       " 4,\n",
       " 196,\n",
       " 33,\n",
       " 36,\n",
       " 197,\n",
       " 10,\n",
       " 23,\n",
       " 198,\n",
       " 14,\n",
       " 57,\n",
       " 67,\n",
       " 72,\n",
       " 199,\n",
       " 200,\n",
       " 92,\n",
       " 14,\n",
       " 24,\n",
       " 6,\n",
       " 201,\n",
       " 202,\n",
       " 16,\n",
       " 3,\n",
       " 203,\n",
       " 4,\n",
       " 14,\n",
       " 37,\n",
       " 10,\n",
       " 204,\n",
       " 205,\n",
       " 19,\n",
       " 5,\n",
       " 84,\n",
       " 4,\n",
       " 206,\n",
       " 49,\n",
       " 207,\n",
       " 208,\n",
       " 26,\n",
       " 3,\n",
       " 93,\n",
       " 7,\n",
       " 3,\n",
       " 209,\n",
       " 94,\n",
       " 4,\n",
       " 9,\n",
       " 210,\n",
       " 7,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 2,\n",
       " 5,\n",
       " 95,\n",
       " 4,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 20,\n",
       " 217,\n",
       " 70,\n",
       " 42,\n",
       " 218,\n",
       " 26,\n",
       " 43,\n",
       " 219,\n",
       " 8,\n",
       " 220,\n",
       " 96,\n",
       " 221,\n",
       " 25,\n",
       " 6,\n",
       " 58,\n",
       " 42,\n",
       " 97,\n",
       " 222,\n",
       " 17,\n",
       " 223,\n",
       " 16,\n",
       " 5,\n",
       " 98,\n",
       " 224,\n",
       " 15,\n",
       " 9,\n",
       " 59,\n",
       " 60,\n",
       " 8,\n",
       " 225,\n",
       " 226,\n",
       " 4,\n",
       " 227,\n",
       " 77,\n",
       " 36,\n",
       " 61,\n",
       " 99,\n",
       " 228,\n",
       " 229,\n",
       " 26,\n",
       " 3,\n",
       " 230,\n",
       " 4,\n",
       " 100,\n",
       " 6,\n",
       " 25,\n",
       " 10,\n",
       " 12,\n",
       " 231,\n",
       " 7,\n",
       " 8,\n",
       " 232,\n",
       " 4,\n",
       " 87,\n",
       " 17,\n",
       " 101,\n",
       " 15,\n",
       " 9,\n",
       " 233,\n",
       " 3,\n",
       " 94,\n",
       " 2,\n",
       " 102,\n",
       " 57,\n",
       " 6,\n",
       " 17,\n",
       " 12,\n",
       " 234,\n",
       " 2,\n",
       " 235,\n",
       " 44,\n",
       " 2,\n",
       " 236,\n",
       " 5,\n",
       " 237,\n",
       " 238,\n",
       " 11,\n",
       " 74,\n",
       " 6,\n",
       " 8,\n",
       " 95,\n",
       " 103,\n",
       " 3,\n",
       " 239,\n",
       " 240,\n",
       " 104,\n",
       " 3,\n",
       " 241,\n",
       " 10,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 5,\n",
       " 246,\n",
       " 7,\n",
       " 247,\n",
       " 89,\n",
       " 6,\n",
       " 248,\n",
       " 249,\n",
       " 81,\n",
       " 250,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 251,\n",
       " 8,\n",
       " 252,\n",
       " 82,\n",
       " 7,\n",
       " 3,\n",
       " 18,\n",
       " 253,\n",
       " 254,\n",
       " 23,\n",
       " 255,\n",
       " 256,\n",
       " 50,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 6,\n",
       " 261,\n",
       " 98,\n",
       " 105,\n",
       " 27,\n",
       " 106,\n",
       " 17,\n",
       " 107,\n",
       " 262,\n",
       " 7,\n",
       " 263,\n",
       " 264,\n",
       " 6,\n",
       " 265,\n",
       " 62,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 88,\n",
       " 40,\n",
       " 40,\n",
       " 272,\n",
       " 6,\n",
       " 108,\n",
       " 17,\n",
       " 273,\n",
       " 5,\n",
       " 109,\n",
       " 274,\n",
       " 275,\n",
       " 109,\n",
       " 276,\n",
       " 7,\n",
       " 8,\n",
       " 277,\n",
       " 103,\n",
       " 8,\n",
       " 278,\n",
       " 52,\n",
       " 10,\n",
       " 279,\n",
       " 280,\n",
       " 8,\n",
       " 281,\n",
       " 17,\n",
       " 101,\n",
       " 15,\n",
       " 282,\n",
       " 42,\n",
       " 36,\n",
       " 86,\n",
       " 110,\n",
       " 50,\n",
       " 91,\n",
       " 75,\n",
       " 16,\n",
       " 283,\n",
       " 37,\n",
       " 6,\n",
       " 42,\n",
       " 53,\n",
       " 11,\n",
       " 32,\n",
       " 25,\n",
       " 2,\n",
       " 102,\n",
       " 14,\n",
       " 57,\n",
       " 54,\n",
       " 9,\n",
       " 44,\n",
       " 12,\n",
       " 105,\n",
       " 27,\n",
       " 106,\n",
       " 15,\n",
       " 10,\n",
       " 284,\n",
       " 5,\n",
       " 285,\n",
       " 286,\n",
       " 63,\n",
       " 9,\n",
       " 12,\n",
       " 287,\n",
       " 288,\n",
       " 2,\n",
       " 111,\n",
       " 110,\n",
       " 289,\n",
       " 44,\n",
       " 3,\n",
       " 39,\n",
       " 3,\n",
       " 112,\n",
       " 290,\n",
       " 4,\n",
       " 9,\n",
       " 291,\n",
       " 68,\n",
       " 4,\n",
       " 292,\n",
       " 16,\n",
       " 293,\n",
       " 14,\n",
       " 294,\n",
       " 295,\n",
       " 7,\n",
       " 18,\n",
       " 296,\n",
       " 15,\n",
       " 297,\n",
       " 298,\n",
       " 24,\n",
       " 299,\n",
       " 26,\n",
       " 8,\n",
       " 300,\n",
       " 11,\n",
       " 47,\n",
       " 9,\n",
       " 28,\n",
       " 10,\n",
       " 301,\n",
       " 2,\n",
       " 302,\n",
       " 303,\n",
       " 7,\n",
       " 304,\n",
       " 17,\n",
       " 305,\n",
       " 13,\n",
       " 306,\n",
       " 307,\n",
       " 97,\n",
       " 32,\n",
       " 308,\n",
       " 45,\n",
       " 15,\n",
       " 61,\n",
       " 55,\n",
       " 18,\n",
       " 113,\n",
       " 21,\n",
       " 6,\n",
       " 28,\n",
       " 11,\n",
       " 309,\n",
       " 8,\n",
       " 34,\n",
       " 12,\n",
       " 310,\n",
       " 2,\n",
       " 64,\n",
       " 112,\n",
       " 63,\n",
       " 29,\n",
       " 30,\n",
       " 5,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 15,\n",
       " 80,\n",
       " 111,\n",
       " 16,\n",
       " 3,\n",
       " 39,\n",
       " 76,\n",
       " 37,\n",
       " 59,\n",
       " 314,\n",
       " 2,\n",
       " 114,\n",
       " 13,\n",
       " 12,\n",
       " 115,\n",
       " 2,\n",
       " 60,\n",
       " 108,\n",
       " 315,\n",
       " 22,\n",
       " 32,\n",
       " 316,\n",
       " 116,\n",
       " 45,\n",
       " 44,\n",
       " 96,\n",
       " 5,\n",
       " 117,\n",
       " 118,\n",
       " 4,\n",
       " 58,\n",
       " 62,\n",
       " 29,\n",
       " 119,\n",
       " 317,\n",
       " 38,\n",
       " 120,\n",
       " 6,\n",
       " 121,\n",
       " 122,\n",
       " 47,\n",
       " 318,\n",
       " 15,\n",
       " 56,\n",
       " 59,\n",
       " 319,\n",
       " 320,\n",
       " 51,\n",
       " 321,\n",
       " 24,\n",
       " 39,\n",
       " 322,\n",
       " 13,\n",
       " 12,\n",
       " 123,\n",
       " 2,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 61,\n",
       " 60,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 2,\n",
       " 43,\n",
       " 329,\n",
       " 3,\n",
       " 330,\n",
       " 331,\n",
       " 107,\n",
       " 332,\n",
       " 333,\n",
       " 2,\n",
       " 20,\n",
       " 334,\n",
       " 38,\n",
       " 335,\n",
       " 6,\n",
       " 63,\n",
       " 7,\n",
       " 336,\n",
       " 13,\n",
       " 337,\n",
       " 338,\n",
       " 71,\n",
       " 7,\n",
       " 339,\n",
       " 16,\n",
       " 340,\n",
       " 341,\n",
       " 5,\n",
       " 124,\n",
       " 9,\n",
       " 342,\n",
       " 27,\n",
       " 343,\n",
       " 13,\n",
       " 2,\n",
       " 344,\n",
       " 125,\n",
       " 345,\n",
       " 6,\n",
       " 346,\n",
       " 5,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 38,\n",
       " 3,\n",
       " 52,\n",
       " 4,\n",
       " 13,\n",
       " 10,\n",
       " 19,\n",
       " 350,\n",
       " 124,\n",
       " 31,\n",
       " 5,\n",
       " 351,\n",
       " 45,\n",
       " 11,\n",
       " 18,\n",
       " 113,\n",
       " 31,\n",
       " 19,\n",
       " 115,\n",
       " 11,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 6,\n",
       " 126,\n",
       " 53,\n",
       " 2,\n",
       " 92,\n",
       " 14,\n",
       " 18,\n",
       " 24,\n",
       " 3,\n",
       " 45,\n",
       " 357,\n",
       " 5,\n",
       " 117,\n",
       " 118,\n",
       " 4,\n",
       " 58,\n",
       " 62,\n",
       " 29,\n",
       " 119,\n",
       " 121,\n",
       " 122,\n",
       " 6,\n",
       " 120,\n",
       " 46,\n",
       " 358,\n",
       " 359,\n",
       " 19,\n",
       " 125,\n",
       " 360,\n",
       " 2,\n",
       " 64,\n",
       " 361,\n",
       " 30,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 2,\n",
       " 64,\n",
       " 14,\n",
       " 365,\n",
       " 23,\n",
       " 366,\n",
       " 127,\n",
       " 2,\n",
       " 116,\n",
       " 367,\n",
       " 11,\n",
       " 22,\n",
       " 368,\n",
       " 128,\n",
       " 65,\n",
       " 129,\n",
       " 65,\n",
       " 369,\n",
       " 11,\n",
       " 126,\n",
       " 31,\n",
       " 370,\n",
       " 371,\n",
       " 5,\n",
       " 372,\n",
       " 373,\n",
       " 123,\n",
       " 30,\n",
       " 374,\n",
       " 128,\n",
       " 65,\n",
       " 129,\n",
       " 375,\n",
       " 56,\n",
       " 127,\n",
       " 2,\n",
       " 41,\n",
       " 4,\n",
       " 46,\n",
       " 376,\n",
       " 104,\n",
       " 23,\n",
       " 377,\n",
       " 378,\n",
       " 100,\n",
       " 54,\n",
       " 31,\n",
       " 379,\n",
       " 3,\n",
       " 130,\n",
       " 19,\n",
       " 380,\n",
       " 131,\n",
       " 132,\n",
       " 381,\n",
       " 99,\n",
       " 3,\n",
       " 25,\n",
       " 2,\n",
       " 382,\n",
       " 66,\n",
       " 43,\n",
       " 383,\n",
       " 3,\n",
       " 31,\n",
       " 384,\n",
       " 9,\n",
       " 11,\n",
       " 41,\n",
       " 66,\n",
       " 133,\n",
       " 30,\n",
       " 3,\n",
       " 385,\n",
       " 4,\n",
       " 46,\n",
       " 386,\n",
       " 19,\n",
       " 5,\n",
       " 387,\n",
       " 388,\n",
       " 130,\n",
       " 9,\n",
       " 11,\n",
       " 41,\n",
       " 66,\n",
       " 133,\n",
       " 10,\n",
       " 389,\n",
       " 15,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 3,\n",
       " 393,\n",
       " 2,\n",
       " 114,\n",
       " 394,\n",
       " 6,\n",
       " 48,\n",
       " 395,\n",
       " 4,\n",
       " 14,\n",
       " 43,\n",
       " 396,\n",
       " 90,\n",
       " 397,\n",
       " 27,\n",
       " 93,\n",
       " 19,\n",
       " 398,\n",
       " 399,\n",
       " 46,\n",
       " 34,\n",
       " 2,\n",
       " 55,\n",
       " 18,\n",
       " 9,\n",
       " 400,\n",
       " 22,\n",
       " 21,\n",
       " 401,\n",
       " 83,\n",
       " 28,\n",
       " 2,\n",
       " 131,\n",
       " 132,\n",
       " 7,\n",
       " 3,\n",
       " 51]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1636d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokenizer.pkl\",'wb')  as f :\n",
    "    pickle.dump(tokenizer,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7ee5c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 100\n",
    "def create_dataset(seq,window_size = max_seq_length):\n",
    "    input ,labels = [],[]\n",
    "    for i in range(len(seq) -window_size):\n",
    "        input.append(seq[i:i+window_size])\n",
    "        labels.append(seq[i+1:i+window_size+1])\n",
    "    return np.array(input) , np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d383f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data , y_data = create_dataset(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c141b7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f319997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35ecebf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 47,  32, 134,  67,  68,   4,  33,  48,  20,  69,   2,  21,   9,\n",
       "       135,  22,   5, 136, 137,  12,   8, 138,  34,  49,   3,  70,  13,\n",
       "        35, 139,  49, 140, 141,  71,  33,  16, 142, 143, 144,  72,  23,\n",
       "         3,  24,  73, 145,   2,  48,   7, 146, 147, 148, 149,  36,   4,\n",
       "       150,  33,  50,  10,  74,  75,  16,  76,  37,  73, 151,  13, 152,\n",
       "         5, 153,  25,   2, 154, 155,  14, 156,   7, 157,  13,  12, 158,\n",
       "        26, 159,   7,   5, 160, 161, 162, 163,  77,  27,  78,  12,   5,\n",
       "       164, 165,  10,  79, 166,  38,   8,  34,  80])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "833546b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 32, 134,  67,  68,   4,  33,  48,  20,  69,   2,  21,   9, 135,\n",
       "        22,   5, 136, 137,  12,   8, 138,  34,  49,   3,  70,  13,  35,\n",
       "       139,  49, 140, 141,  71,  33,  16, 142, 143, 144,  72,  23,   3,\n",
       "        24,  73, 145,   2,  48,   7, 146, 147, 148, 149,  36,   4, 150,\n",
       "        33,  50,  10,  74,  75,  16,  76,  37,  73, 151,  13, 152,   5,\n",
       "       153,  25,   2, 154, 155,  14, 156,   7, 157,  13,  12, 158,  26,\n",
       "       159,   7,   5, 160, 161, 162, 163,  77,  27,  78,  12,   5, 164,\n",
       "       165,  10,  79, 166,  38,   8,  34,  80,  81])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e45d0fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, max_len, d_model):\n",
    "        super().__init__()\n",
    "        pos = np.arange(max_len)[:, np.newaxis]\n",
    "        i = np.arange(d_model)[np.newaxis, :]\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "        angle_rads = pos * angle_rates\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        self.pos_encoding = tf.cast(angle_rads[np.newaxis, ...], dtype=tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        return x + self.pos_encoding[:, :tf.shape(x)[1], :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa15f732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_block(embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "    inputs = layers.Input(shape=(None, embed_dim))\n",
    "    attn_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(inputs, inputs)\n",
    "    attn_output = layers.Dropout(dropout)(attn_output)\n",
    "    out1 = layers.LayerNormalization(epsilon=1e-6)(inputs + attn_output)\n",
    "\n",
    "    ffn = tf.keras.Sequential([\n",
    "        layers.Dense(ff_dim, activation='relu'),\n",
    "        layers.Dense(embed_dim),\n",
    "    ])\n",
    "    ffn_output = ffn(out1)\n",
    "    ffn_output = layers.Dropout(dropout)(ffn_output)\n",
    "    out2 = layers.LayerNormalization(epsilon=1e-6)(out1 + ffn_output)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32afce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 500\n",
    "max_seq_len = 100\n",
    "embed_dim = 100\n",
    "num_heads = 8\n",
    "ff_dim = 200\n",
    "num_layers = 20\n",
    "batch_size = 16\n",
    "epoch = 5\n",
    "\n",
    "def build_gpt_model():\n",
    "    inputs = layers.Input(shape=(max_seq_len,))\n",
    "    x = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\n",
    "    x = PositionalEncoding(max_seq_len, embed_dim)(x)\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        transformer = transformer_block(embed_dim, num_heads, ff_dim)\n",
    "        x = transformer(x)\n",
    "\n",
    "    outputs = layers.Dense(vocab_size, activation='softmax')(x)\n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d3e901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_gpt_model()\n",
    "model.compile(optimizer='adam' , loss = 'mse' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bb3e17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42/42 [==============================] - 22s 271ms/step - loss: 5.4226 - accuracy: 0.0334 - val_loss: 6.9260 - val_accuracy: 0.0468\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 10s 236ms/step - loss: 5.4226 - accuracy: 0.0339 - val_loss: 7.0878 - val_accuracy: 0.0468\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 9s 222ms/step - loss: 5.4170 - accuracy: 0.0339 - val_loss: 7.1022 - val_accuracy: 0.0468\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 10s 241ms/step - loss: 5.4171 - accuracy: 0.0344 - val_loss: 7.1002 - val_accuracy: 0.0468\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 10s 241ms/step - loss: 5.4165 - accuracy: 0.0343 - val_loss: 7.1767 - val_accuracy: 0.0468\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 11s 261ms/step - loss: 5.4157 - accuracy: 0.0352 - val_loss: 7.2062 - val_accuracy: 0.0468\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 11s 255ms/step - loss: 5.4136 - accuracy: 0.0348 - val_loss: 7.1739 - val_accuracy: 0.0468\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 12s 281ms/step - loss: 5.4110 - accuracy: 0.0351 - val_loss: 7.2243 - val_accuracy: 0.0468\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 11s 263ms/step - loss: 5.4118 - accuracy: 0.0353 - val_loss: 7.2375 - val_accuracy: 0.0468\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 12s 300ms/step - loss: 5.4110 - accuracy: 0.0356 - val_loss: 7.3326 - val_accuracy: 0.0440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17bb6fc6fe0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the model is compiled with the correct loss function\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_data, y_data, batch_size=batch_size, epochs=10, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e17ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 240). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gpt_model_class\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gpt_model_class\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('gpt_model_class')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df41dd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 256)          1280000   \n",
      "                                                                 \n",
      " positional_encoding (Positi  (None, 100, 256)         0         \n",
      " onalEncoding)                                                   \n",
      "                                                                 \n",
      " model (Functional)          (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_1 (Functional)        (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_2 (Functional)        (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_3 (Functional)        (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_4 (Functional)        (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_5 (Functional)        (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_6 (Functional)        (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_7 (Functional)        (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_8 (Functional)        (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_9 (Functional)        (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_10 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_11 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_12 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_13 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_14 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_15 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_16 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_17 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_18 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_19 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_20 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_21 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_22 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_23 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_24 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_25 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_26 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_27 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_28 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_29 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_30 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_31 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_32 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_33 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_34 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_35 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_36 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_37 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_38 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_39 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_40 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_41 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_42 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_43 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_44 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_45 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_46 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_47 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_48 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_49 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_50 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_51 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_52 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_53 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_54 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_55 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_56 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_57 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_58 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_59 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_60 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_61 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_62 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_63 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_64 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_65 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_66 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_67 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_68 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_69 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_70 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_71 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_72 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_73 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_74 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_75 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_76 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_77 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_78 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_79 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_80 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_81 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_82 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_83 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_84 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_85 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_86 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_87 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_88 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_89 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_90 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_91 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_92 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_93 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_94 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " model_95 (Functional)       (None, None, 256)         2630144   \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 100, 5000)         1285000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 255,058,824\n",
      "Trainable params: 255,058,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5ccd6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "model = tf.keras.models.load_model('gpt_model_class', custom_objects={'PositionalEncoding': PositionalEncoding, 'transformer_block': transformer_block})\n",
    "with open(\"tokenizer.pkl\",'rb') as f :\n",
    "    tokenizer = pickle.load(f)  \n",
    "\n",
    "max_seq_len=16    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9866a387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed text:  my name is sudhanshu \n",
      "Generated text:  my name is sudhanshu      dual               \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def generate_text(seed_text, next_words, model, tokenizer, max_seq_len, temperature=1.0):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        # Ensure padding to max_seq_len (100 here)\n",
    "        token_list = pad_sequences([token_list], maxlen=max_seq_len, padding='pre')\n",
    "        \n",
    "        # Predict the next word\n",
    "        predicted = model.predict(token_list, verbose=0)\n",
    "\n",
    "        # Apply temperature scaling\n",
    "        predicted = predicted[0] / temperature  # Scale the predictions\n",
    "        predicted = np.exp(predicted) / np.sum(np.exp(predicted))  # Softmax-like scaling for randomness\n",
    "        \n",
    "        # Ensure predicted is 1D\n",
    "        predicted = predicted.flatten()  # Make sure it is 1D\n",
    "        \n",
    "        # Get the index of the predicted word\n",
    "        predicted_word_index = np.random.choice(range(len(predicted)), p=predicted)\n",
    "        \n",
    "        # Retrieve the actual word from the tokenizer's word index\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_word_index:\n",
    "                output_word = word\n",
    "                break\n",
    "        \n",
    "        # Append the predicted word to the seed text\n",
    "        seed_text += \" \" + output_word\n",
    "    \n",
    "    return seed_text\n",
    "\n",
    "# Example usage\n",
    "seed_text = \"my name is sudhanshu \"\n",
    "next_words = 20\n",
    "temperature = 0.5  # Adjust temperature for creativity\n",
    "generated_text = generate_text(seed_text, next_words, model, tokenizer, max_seq_len=100, temperature=temperature)\n",
    "\n",
    "print(\"Seed text: \", seed_text) \n",
    "print(\"Generated text: \", generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b960f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
