{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "664b635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = [3,4,5,6,7,6,7,5,6,7,8,9]\n",
    "output = [3,4,5,56,6,7,8,9,0,0,7,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ba40d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 3),\n",
       " (4, 4),\n",
       " (5, 5),\n",
       " (6, 56),\n",
       " (7, 6),\n",
       " (6, 7),\n",
       " (7, 8),\n",
       " (5, 9),\n",
       " (6, 0),\n",
       " (7, 0),\n",
       " (8, 7),\n",
       " (9, 4)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(input,output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07d2e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 0.0\n",
    "b= 0.0\n",
    "lr = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ce8189e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | Loss : 4765.74205765353  | w : -0.02274495796089715 , b: 0.234673196595955\n",
      "epoch 10 | Loss : 4741.506151986847  | w : -0.2521193533024988 , b: 2.4057629903058793\n",
      "epoch 20 | Loss : 4727.5764121731045  | w : -0.45165831217269514 , b: 4.294452424910856\n",
      "epoch 30 | Loss : 4720.637761491353  | w : -0.625242621998145 , b: 5.937474187862894\n",
      "epoch 40 | Loss : 4718.521124029562  | w : -0.7762482841915561 , b: 7.3667830324367145\n",
      "epoch 50 | Loss : 4719.645961229264  | w : -0.9076121732285329 , b: 8.610177258394142\n",
      "epoch 60 | Loss : 4722.86919446392  | w : -1.021889155245383 , b: 9.691839354737802\n",
      "epoch 70 | Loss : 4727.371905119765  | w : -1.1213017770443898 , b: 10.632806319391081\n",
      "epoch 80 | Loss : 4732.5744895107555  | w : -1.2077834918966002 , b: 11.45137880294375\n",
      "epoch 90 | Loss : 4738.073230935231  | w : -1.2830162628308601 , b: 12.163477033806155\n",
      "epoch 100 | Loss : 4743.592978119958  | w : -1.3484632747468397 , b: 12.78295044707873\n",
      "epoch 110 | Loss : 4748.951924222351  | w : -1.4053973915624105 , b: 13.32184703903742\n",
      "epoch 120 | Loss : 4754.035466376141  | w : -1.4549259118519318 , b: 13.790647685848898\n",
      "epoch 130 | Loss : 4758.776870308799  | w : -1.4980121044421466 , b: 14.198469983726234\n",
      "epoch 140 | Loss : 4763.143026709327  | w : -1.5354939428065748 , b: 14.553245574965626\n",
      "epoch 150 | Loss : 4767.124010314165  | w : -1.568100402619321 , b: 14.861874408637483\n",
      "epoch 160 | Loss : 4770.725472785724  | w : -1.5964656394357002 , b: 15.130358936112708\n",
      "epoch 170 | Loss : 4773.963141850472  | w : -1.6211413222381241 , b: 15.363920851362149\n",
      "epoch 180 | Loss : 4776.858881098182  | w : -1.6426073627195548 , b: 15.567102646484445\n",
      "epoch 190 | Loss : 4779.4379018796035  | w : -1.661281248975914 , b: 15.743855957592697\n",
      "epoch 200 | Loss : 4781.726821881223  | w : -1.67752616513626 , b: 15.89761841927843\n",
      "epoch 210 | Loss : 4783.752342520468  | w : -1.6916580548475846 , b: 16.031380522378022\n",
      "epoch 220 | Loss : 4785.540375576914  | w : -1.7039517659903065 , b: 16.14774377534282\n",
      "epoch 230 | Loss : 4787.115493203286  | w : -1.7146463961316352 , b: 16.24897130038005\n",
      "epoch 240 | Loss : 4788.500608229515  | w : -1.7239499426792984 , b: 16.33703184839743\n",
      "epoch 250 | Loss : 4789.7168161915615  | w : -1.7320433481753927 , b: 16.413638088787764\n",
      "epoch 260 | Loss : 4790.7833488274155  | w : -1.739084019406371 , b: 16.48027991874302\n",
      "epoch 270 | Loss : 4791.717602427381  | w : -1.7452088887715176 , b: 16.538253439922975\n",
      "epoch 280 | Loss : 4792.535214566707  | w : -1.7505370774497604 , b: 16.588686166039004\n",
      "epoch 290 | Loss : 4793.250170262554  | w : -1.7551722121601419 , b: 16.632558951609486\n",
      "epoch 300 | Loss : 4793.87492414355  | w : -1.759204440574108 , b: 16.67072506837431\n",
      "epoch 310 | Loss : 4794.420529295907  | w : -1.7627121845768805 , b: 16.70392680038117\n",
      "epoch 320 | Loss : 4794.8967664286265  | w : -1.7657636654767186 , b: 16.732809880497726\n",
      "epoch 330 | Loss : 4795.312269162333  | w : -1.768418230825473 , b: 16.757936049121884\n",
      "epoch 340 | Loss : 4795.674642802345  | w : -1.7707275086555239 , b: 16.779793979342028\n",
      "epoch 350 | Loss : 4795.990575064512  | w : -1.7727364115815205 , b: 16.798808781027674\n",
      "epoch 360 | Loss : 4796.265938000211  | w : -1.774484010295525 , b: 16.81535026869383\n",
      "epoch 370 | Loss : 4796.505880902758  | w : -1.7760042934439384 , b: 16.82974015393867\n",
      "epoch 380 | Loss : 4796.714914337283  | w : -1.7773268286648856 , b: 16.84225830233855\n",
      "epoch 390 | Loss : 4796.89698566833  | w : -1.7784773376424177 , b: 16.85314817648938\n",
      "epoch 400 | Loss : 4797.055546600651  | w : -1.7794781963616568 , b: 16.86262157105484\n",
      "epoch 410 | Loss : 4797.193613325129  | w : -1.780348870294181 , b: 16.870862731912126\n",
      "epoch 420 | Loss : 4797.313819893567  | w : -1.7811062929775332 , b: 16.878031939507864\n",
      "epoch 430 | Loss : 4797.418465447148  | w : -1.781765195351686 , b: 16.884268626115553\n",
      "epoch 440 | Loss : 4797.509555904339  | w : -1.7823383922577318 , b: 16.88969408762205\n",
      "epoch 450 | Loss : 4797.58884068237  | w : -1.7828370316707742 , b: 16.894413842583305\n",
      "epoch 460 | Loss : 4797.65784498734  | w : -1.7832708115143432 , b: 16.898519684430592\n",
      "epoch 470 | Loss : 4797.717898165444  | w : -1.7836481682730865 , b: 16.902091466739925\n",
      "epoch 480 | Loss : 4797.770158564111  | w : -1.7839764410720191 , b: 16.90519865628588\n",
      "epoch 490 | Loss : 4797.815635308933  | w : -1.7842620144134833 , b: 16.907901684084973\n",
      "epoch 500 | Loss : 4797.855207361247  | w : -1.7845104423478744 , b: 16.910253120704677\n",
      "epoch 510 | Loss : 4797.889640182444  | w : -1.7847265564930839 , b: 16.912298698696247\n",
      "epoch 520 | Loss : 4797.919600295562  | w : -1.7849145600035392 , b: 16.91407820203673\n",
      "epoch 530 | Loss : 4797.9456680018675  | w : -1.785078109316375 , b: 16.91562623987826\n",
      "epoch 540 | Loss : 4797.968348480458  | w : -1.7852203852646502 , b: 16.916972919653613\n",
      "epoch 550 | Loss : 4797.9880814722255  | w : -1.7853441549406368 , b: 16.91814443262874\n",
      "epoch 560 | Loss : 4798.005249725445  | w : -1.7854518255123617 , b: 16.919163563290677\n",
      "epoch 570 | Loss : 4798.020186358912  | w : -1.7855454910400748 , b: 16.920050132477865\n",
      "epoch 580 | Loss : 4798.033181279514  | w : -1.785626973203129 , b: 16.92082138287097\n",
      "epoch 590 | Loss : 4798.044486774276  | w : -1.7856978567294175 , b: 16.921492314341933\n",
      "epoch 600 | Loss : 4798.054322381975  | w : -1.7857595202163807 , b: 16.922075975682997\n",
      "epoch 610 | Loss : 4798.062879136395  | w : -1.7858131629430258 , b: 16.922583718389642\n",
      "epoch 620 | Loss : 4798.0703232616315  | w : -1.7858598281944391 , b: 16.923025417433312\n",
      "epoch 630 | Loss : 4798.07679938976  | w : -1.7859004235523845 , b: 16.92340966331732\n",
      "epoch 640 | Loss : 4798.082433362255  | w : -1.7859357385466645 , b: 16.92374392915171\n",
      "epoch 650 | Loss : 4798.087334668766  | w : -1.7859664600104994 , b: 16.924034715995987\n",
      "epoch 660 | Loss : 4798.0915985699585  | w : -1.785993185438587 , b: 16.92428767929674\n",
      "epoch 670 | Loss : 4798.0953079452565  | w : -1.7860164346076512 , b: 16.924507738879203\n",
      "epoch 680 | Loss : 4798.098534900959  | w : -1.7860366596854442 , b: 16.924699174631694\n",
      "epoch 690 | Loss : 4798.101342169766  | w : -1.786054254024866 , b: 16.924865709744253\n",
      "epoch 700 | Loss : 4798.103784328713  | w : -1.7860695598141851 , b: 16.925010583120052\n",
      "epoch 710 | Loss : 4798.105908858972  | w : -1.786082874732184 , b: 16.92513661236812\n",
      "epoch 720 | Loss : 4798.107757068074  | w : -1.7860944577376505 , b: 16.925246248602413\n",
      "epoch 730 | Loss : 4798.109364892361  | w : -1.7861045341058006 , b: 16.9253416241129\n",
      "epoch 740 | Loss : 4798.11076359518  | w : -1.7861132998096032 , b: 16.92542459383597\n",
      "epoch 750 | Loss : 4798.111980374397  | w : -1.7861209253312227 , b: 16.925496771430748\n",
      "epoch 760 | Loss : 4798.1130388909405  | w : -1.7861275589776802 , b: 16.925559560662723\n",
      "epoch 770 | Loss : 4798.113959728696  | w : -1.7861333297652402 , b: 16.92561418270524\n",
      "epoch 780 | Loss : 4798.114760794567  | w : -1.7861383499286276 , b: 16.92566169988987\n",
      "epoch 790 | Loss : 4798.115457666603  | w : -1.7861427171038484 , b: 16.92570303636744\n",
      "epoch 800 | Loss : 4798.116063896821  | w : -1.7861465162270926 , b: 16.92573899608164\n",
      "epoch 810 | Loss : 4798.116591274681  | w : -1.7861498211866362 , b: 16.925770278404684\n",
      "epoch 820 | Loss : 4798.117050056289  | w : -1.7861526962598764 , b: 16.92579749173928\n",
      "epoch 830 | Loss : 4798.117449163834  | w : -1.7861551973634575 , b: 16.92582116535137\n",
      "epoch 840 | Loss : 4798.11779635904  | w : -1.7861573731407638 , b: 16.925841759663545\n",
      "epoch 850 | Loss : 4798.118098394109  | w : -1.786159265907993 , b: 16.925859675209903\n",
      "epoch 860 | Loss : 4798.118361143009  | w : -1.7861609124771385 , b: 16.925875260425777\n",
      "epoch 870 | Loss : 4798.118589715698  | w : -1.786162344871948 , b: 16.92588881842446\n",
      "epoch 880 | Loss : 4798.118788557502  | w : -1.786163590950738 , b: 16.925900612892367\n",
      "epoch 890 | Loss : 4798.118961535535  | w : -1.7861646749482074 , b: 16.92591087321736\n",
      "epoch 900 | Loss : 4798.119112013937  | w : -1.7861656179467755 , b: 16.92591979895018\n",
      "epoch 910 | Loss : 4798.119242919263  | w : -1.7861664382866058 , b: 16.925927563685338\n",
      "epoch 920 | Loss : 4798.119356797418  | w : -1.7861671519223012 , b: 16.925934318437417\n",
      "epoch 930 | Loss : 4798.119455863153  | w : -1.7861677727331944 , b: 16.925940194578004\n",
      "epoch 940 | Loss : 4798.119542043151  | w : -1.7861683127932952 , b: 16.92594530639082\n",
      "epoch 950 | Loss : 4798.119617013491  | w : -1.7861687826061108 , b: 16.92594975329435\n",
      "epoch 960 | Loss : 4798.119682232235  | w : -1.7861691913089226 , b: 16.925953621775406\n",
      "epoch 970 | Loss : 4798.1197389677955  | w : -1.7861695468504948 , b: 16.92595698707116\n",
      "epoch 980 | Loss : 4798.119788323605  | w : -1.7861698561456782 , b: 16.925959914632518\n",
      "epoch 990 | Loss : 4798.119831259564  | w : -1.786170125209881 , b: 16.92596246139692\n",
      "4.4227721078103635\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    total_loss = 0\n",
    "    for x,y in zip(input,output):\n",
    "        Y_pred = w*x+b\n",
    "        error = Y_pred-y\n",
    "        loss = error**2\n",
    "        total_loss = total_loss + loss\n",
    "        \n",
    "        dw = 2*error*x\n",
    "        db = 2*error\n",
    "        \n",
    "        w = w -lr*dw\n",
    "        b = b - lr*db\n",
    "        \n",
    "    if epoch %10 ==0 :\n",
    "        print(f\"epoch {epoch} | Loss : {total_loss}  | w : {w} , b: {b}\")\n",
    "        \n",
    "test_data = 7 \n",
    "prediction = w*test_data + b \n",
    "print(prediction)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92178c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = [1,2,3,4,5]\n",
    "output = [2,4,6,8,10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a8bf84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 , b1 = .1,0.0\n",
    "w2,b2 = -0.1 , 0.0\n",
    "w3,w4 = .1 , .1 \n",
    "b3 = 0.0\n",
    "lr = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31bf20a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return max(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30e8010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_derivative(x):\n",
    "    return 1 if x>0 else 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "596a7c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | Loss : 197.58784675778605 \n",
      "epoch 10 | Loss : 0.7822743866736906 \n",
      "epoch 20 | Loss : 0.2777331306080438 \n",
      "epoch 30 | Loss : 0.09441733364350127 \n",
      "epoch 40 | Loss : 0.03110053083599192 \n",
      "epoch 50 | Loss : 0.010038059173204952 \n",
      "epoch 60 | Loss : 0.00320027527189278 \n",
      "epoch 70 | Loss : 0.0010129806992875082 \n",
      "epoch 80 | Loss : 0.0003193181207800499 \n",
      "epoch 90 | Loss : 0.00010042211687133479 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17.99692772369434"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    total_loss = 0 \n",
    "    for x,y in zip(input,output):\n",
    "        z1 = w1*x + b1\n",
    "        h1 = relu(z1)\n",
    "        \n",
    "        z2 = w2*x + b2\n",
    "        h2 = relu(z2)\n",
    "        \n",
    "        Y_pred = w3*h1 + w4*h2 + b3\n",
    "        \n",
    "        error = Y_pred - y \n",
    "        loss  = error**2\n",
    "        total_loss = total_loss + loss\n",
    "        \n",
    "        dl_dy = 2*error\n",
    "        \n",
    "        dw3 = dl_dy * h1\n",
    "        dw4 = dl_dy * h2\n",
    "        db3 = dl_dy\n",
    "        \n",
    "        dh1 = dl_dy * w3\n",
    "        dh2 = dl_dy * w4\n",
    "        \n",
    "        dz1 = dh1* relu_derivative(z1)\n",
    "        dz2 = dh2* relu_derivative(z2)\n",
    "        \n",
    "        dw1 = dz1 * x\n",
    "        db1 = dz1\n",
    "        \n",
    "        dw2 = dz2 * x\n",
    "        db2 = dz2\n",
    "        \n",
    "        w1 = w1 - lr*dw1\n",
    "        w2 = w2 - lr*dw2\n",
    "        w3 = w3 - lr*dw3\n",
    "        w4 = w4 - lr*dw4\n",
    "        \n",
    "        \n",
    "        b1 = b1 - lr*db1\n",
    "        b2 = b2 - lr*db2\n",
    "        b3 = b3 - lr*db3\n",
    "        \n",
    "    if epoch %10 ==0 :\n",
    "        print(f\"epoch {epoch} | Loss : {total_loss} \")\n",
    "        \n",
    "        \n",
    "def prediction(x):\n",
    "    z1 = w1*x + b1\n",
    "    h1 = relu(z1)\n",
    "        \n",
    "    z2 = w2*x + b2\n",
    "    h2 = relu(z2)\n",
    "        \n",
    "    y_output = w3*h1 + w4*h2 + b3\n",
    "    return y_output     \n",
    "                \n",
    "prediction(9)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e9e4ef0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m \n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d8292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbace8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(input,dtype=float)\n",
    "y = np.array(output, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c92018",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Dense(20,activation='relu',input_shape = [1]),\n",
    "                    tf.keras.layers.Dense(1) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fba4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x,y,epochs=1000,verbose=1)\n",
    "model.save(\"euron_gen_ai_first.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12450441",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"euron_gen_ai_first.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9d62fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d92b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'help'\n",
    "char2idx = {'h':0 , 'e' : 1 , \"l\":2 , \"p\" :3}\n",
    "idx2char = {v : k for k , v in char2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c32f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_seq = [char2idx[c] for c in data[:-1]]\n",
    "target_seq = [char2idx[c] for c in data [1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48e02c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d7e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.one_hot(input_seq,depth=4 )\n",
    "x = tf.expand_dims(x , axis=0)\n",
    "y = tf.expand_dims(target_seq , axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3916967",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f47fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.LSTM(8,return_sequences=True , input_shape =(3,4) ) , \n",
    "                     tf.keras.layers.Dense(4,activation='linear')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5110ba",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407d6825",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam' ,loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7760c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(201):\n",
    "    model.train_on_batch(x,y)\n",
    "    \n",
    "    if epoch % 50  == 0 :\n",
    "        output = model(x)\n",
    "        print(output)\n",
    "        pred = tf.argmax(output,axis = -1).numpy()[0]\n",
    "        pred_char = \"\".join([idx2char[i] for i in pred] )\n",
    "        print(f\"epoch : {epoch} , prediction : {pred_char} , loss : {loss} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32f92b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('euron_lstm.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
